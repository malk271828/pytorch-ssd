name: SSD Project

# conda_env: my_env.yaml
# Can have a docker_env instead of a conda_env, e.g.
# docker_env:
#    image:  mlflow-docker-example

# memo:
# Do NOT use ~/ for specifying an absolute path.

# execute command:
# >>> mlflow run . --no-conda --entry-point <entry point>

entry_points:
  train_mb1:
    parameters:
      model_type: {type: str, default: "mb1-ssd"}
      base_net: {type: str, default: "models/mobilenet_v1_with_relu_69_5.pth"}
      dataset_path1: {type: str, default: "/Users/tsuchiya/datasets/VOCdevkit/VOC2007/"}
      dataset_path2: {type: str, default: "/Users/tsuchiya/datasets/VOCdevkit/VOC2012/"}
      num_epochs: {type: int, default: 200}
      lr: {type: float, default: 0.01}
      batch_size: {type: int, default: 24}
      t_max: {type: int, default: 200}
      scheduler: {type: str, default: "cosine"}
    command: "python train_ssd.py --datasets {dataset_path1} {dataset_path2} --validation_dataset {dataset_path1} --net {model_type} --base_net {base_net}  --batch_size {batch_size} --num_epochs {num_epochs} --scheduler {scheduler} --lr {lr} --t_max {t_max}"

  train_vgg:
    parameters:
      model_type: {type: str, default: "vgg16-ssd"}
      base_net: {type: str, default: "models/vgg16_reducedfc.pth"}
      dataset_path1: {type: str, default: "/Users/tsuchiya/datasets/VOCdevkit/VOC2007/"}
      dataset_path2: {type: str, default: "/Users/tsuchiya/datasets/VOCdevkit/VOC2012/"}
      num_epochs: {type: int, default: 200}
      batch_size: {type: int, default: 24}
      milestones: {type: str, default: "120,160"}
      scheduler: {type: str, default: "multi-step"}
    command: "python train_ssd.py --datasets {dataset_path1} {dataset_path2} --validation_dataset {dataset_path1} --net {model_type} --base_net {base_net}  --batch_size {batch_size} --num_epochs {num_epochs} --scheduler {scheduler} --milestones {milestones}"

  eval:
    parameters:
      model_type: {type: str, default: "mb1-ssd"}
      model_path: {type: str, default: "models/mobilenet-v1-ssd-mp-0_675.pth"}
      dataset_path: {type: str, default: "/Users/tsuchiya/datasets/VOCdevkit/VOC2007/"}
      label_path: {type: str, default: "models/voc-model-labels.txt"}
    command: "python eval_ssd.py --net {model_type} --dataset {dataset_path} --trained_model {model_path} --label_file {label_path}"

  distill:
    parameters:
      model_type: {type: str, default: "mb1-ssd"}
      base_net: {type: str, default: "models/mobilenet_v1_with_relu_69_5.pth"}
      dataset_path1: {type: str, default: "/Users/tsuchiya/datasets/VOCdevkit/VOC2007/"}
      dataset_path2: {type: str, default: "/Users/tsuchiya/datasets/VOCdevkit/VOC2012/"}
      num_epochs: {type: int, default: 200}
      lr: {type: float, default: 0.01}
      batch_size: {type: int, default: 24}
      t_max: {type: int, default: 200}
      scheduler: {type: str, default: "cosine"}
    command: "python train_ssd.py --datasets {dataset_path1} {dataset_path2} --validation_dataset {dataset_path1} --net {model_type} --base_net {base_net}  --batch_size {batch_size} --num_epochs {num_epochs} --scheduler {scheduler} --lr {lr} --t_max {t_max}"

  train_cifar:
    parameters:
      data_path: {type:str, default: "/Users/tsuchiya/datasets/data.cifar10/"}
      num_epochs: {type: int, default: 180}
      lr: {type: float, default: 0.01}
      batch-size: {type: int, default: 256}
      compress_path: {type:str, default: "./vgg16_cifar_baseline_training.yaml"}
    command: "python compress_classifier.py --arch vgg16_cifar {data_path} -p=50 --lr={lr} --batch-size {batch-size} --epochs={num_epochs} --compress={compress_path} -j=1 --deterministic"

  distill_cifar:
    parameters:
      data_path: {type: str, default: "/Users/tsuchiya/datasets/data.cifar10/"}
      num_epochs: {type: int, default: 180}
      lr: {type: float, default: 0.01}
      compress_path: {type: str, default: "./vgg16_cifar_baseline_training.yaml"}
      teacher_checkpoint_path: {type: str, default: "logs/2020.06.23-133816/checkpoint.pth.tar"}
    command: "python compress_classifier.py --arch vgg16_cifar {data_path} -p=50 --lr={lr} --epochs={num_epochs} --compress={compress_path}
              -j=1 --deterministic --kd-teacher vgg16_cifar --kd-resume {teacher_checkpoint_path} --kd-temp 5.0 --kd-dw 0.7 --kd-sw 0.3"

  train_ssd:
    parameters:
      data_path: {type: str, default: "/Users/tsuchiya/datasets/VOCdevkit/VOC2007/"}
      num_epochs: {type: int, default: 180}
      lr: {type: float, default: 0.01}
      batch-size: {type: int, default: 24}
      workers: {type: int, default: 0}
      load-serialized: {type: str, default: "--load-serialized"}
      compress_path: {type: str, default: "./ssd_baseline_training.yaml"}
    command: "python compress_classifier.py --arch vgg16-ssd {data_path} -p=50 --lr={lr} --epochs={num_epochs} --compress={compress_path}
              -j={workers} --deterministic --batch-size {batch-size} {load-serialized} --pretrained"
